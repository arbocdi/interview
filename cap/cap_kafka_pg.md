# CAP-теорема: Kafka и шардированный Postgres

## 1. Что такое CAP

**CAP-теорема** утверждает, что в распределённой системе невозможно одновременно гарантировать:

- **C — Consistency (согласованность)**  
  Все клиенты видят одни и те же данные сразу после записи.

- **A — Availability (доступность)**  
  Каждый запрос получает ответ, даже при сбоях.

- **P — Partition tolerance (устойчивость к разделению сети)**  
  Система продолжает работать при сетевых сбоях между узлами.

➡️ При сетевом разделении можно выбрать **либо C, либо A**, но не оба сразу.

В реальном мире **P всегда есть**, потому что сеть может ломаться.

---

## 2. Kafka и CAP

### 2.1 Архитектурные элементы Kafka
- Партиции
- Репликация (leader / followers)
- ISR (in-sync replicas)
- Настройки `acks`
- `min.insync.replicas`

CAP-поведение Kafka определяется **конфигурацией**.

---

### 2.2 Kafka как AP (по умолчанию)

**Конфигурация:**
- `acks = 0` или `acks = 1`

Поведение:
- Продюсер получает ответ сразу после записи в leader
- Реплики могут отставать
- При падении leader возможна потеря данных

CAP:
- ✔️ Availability
- ✔️ Partition tolerance
- ❌ Consistency

Используется для:
- логов
- метрик
- аналитики

---

### 2.3 Kafka как CP

**Конфигурация:**
- `acks = all`
- `min.insync.replicas >= 2`

Поведение:
- Запись считается успешной только если она попала в несколько реплик
- При потере ISR Kafka отказывает в записи

CAP:
- ✔️ Consistency
- ✔️ Partition tolerance
- ❌ Availability

Используется для:
- команд
- event sourcing
- финансовых событий

---

### 2.4 Вывод по Kafka

Kafka **не фиксирует CAP-модель** — её выбирает архитектор:
- строгая надёжность → CP
- высокая доступность → AP

---

## 3. Шардированный Postgres и CAP

### 3.1 Что значит «шардированный Postgres»
- Несколько независимых PostgreSQL
- Данные распределены по shard key
- Координация:
  - на уровне приложения
  - через coordinator / FDW / Citus

Сеть между шардами может ломаться → **P присутствует**.

---

### 3.2 Один шард = одна транзакция

Поведение:
- Классический ACID
- При недоступности шарда транзакция падает

CAP:
- ✔️ Consistency
- ✔️ Partition tolerance
- ❌ Availability

Это **CP**.

---

### 3.3 Транзакции между шардами (2PC)

Формально:
- CP

Практически:
- Высокая латентность
- Риск зависших `prepared transactions`
- Сложное восстановление

Вывод:
> 2PC сохраняет согласованность, но сильно усложняет систему.

---

### 3.4 Отказ от распределённых транзакций

Типичный подход:
- Каждый шард — локально ACID (CP)
- Между шардами — асинхронное взаимодействие
- Используются:
  - Kafka
  - Outbox
  - Saga

CAP на уровне системы:
- ✔️ Availability
- ✔️ Partition tolerance
- ❌ Global Consistency

Это **AP на уровне архитектуры**.

---

## 4. Сравнение Kafka и Postgres

| Система | CAP-профиль |
|------|------------|
| Kafka (acks=1) | AP |
| Kafka (acks=all) | CP |
| Postgres (один шард) | CP |
| Postgres + 2PC | CP (дорого) |
| Postgres + Saga + Kafka | AP (глобально) |

---

## 5. Ключевая идея

**CAP — это не свойство продукта, а результат архитектурного выбора.**

- Kafka может быть и CP, и AP
- Postgres всегда CP локально
- Глобальная согласованность часто переносится в бизнес-логику

---

## 6. Практический паттерн

Пример: перевод денег

- Списание — локальная CP-транзакция
- Зачисление — асинхронно
- Компенсация при ошибке

Результат:
- локально строго
- глобально eventually consistent
- бизнес-инварианты соблюдаются логикой

---

**Итог:**
> В распределённых системах ты не выбираешь CAP — ты платишь за него осознанно.

